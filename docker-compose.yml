version: "3.8"

services:
  manualmind-backend:
    build:
      context: ./rag-manuals
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - API_HOST=0.0.0.0
      - API_PORT=8000
      - LLM_BACKEND=ollama
      - LLM_API_URL=http://ollama:11434
      - LLM_MODEL_NAME=mistral
      - EMBEDDING_MODEL=all-MiniLM-L6-v2
      - INDEX_PATH=/data/faiss.index
      - META_PATH=/data/meta.jsonl
      - API_SECRET_KEY=${API_SECRET_KEY:-change-this-in-production}
      - LOG_LEVEL=INFO
      - CORS_ORIGINS=http://localhost:3000,http://localhost:3001,http://localhost:8501
    volumes:
      - manualmind-data:/data
    depends_on:
      - ollama
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
    restart: unless-stopped

volumes:
  manualmind-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./rag-manuals/data
  ollama-data:
